{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akscent/internships/blob/main/%D0%98%D1%80%D0%B8%D0%BD%D1%8F%D0%BA%D0%BE%D0%B2_%D0%94_%D0%A1_%22%D0%A2%D0%B5%D1%81%D1%82%D0%BE%D0%B2%D0%BE%D0%B5_%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_Data_Engineer_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Тестовое задание на позицию Data Engineer.\n",
        "\n",
        "Задание включает в себя 3 небольших задачи. В каждой задаче **рекомендуется** оставлять комментарии, код должен быть оформлен согласно **PEP8**. Задания необходимо выполнить без использования Pandas и yandex-weather-api.\n",
        "\n",
        "**Перед выполнением тестового задания, необходимо скопировать notebook к себе на диск, и выполнять тестовое в своей копии**."
      ],
      "metadata": {
        "id": "3ffM1IGEysic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "####1. Выгрузка данных из API Яндекс.Погоды и преобразование их в csv\n",
        "\n",
        "Используя API Яндекс.Погоды, необходимо выгрузить прогнозные данные за 7 дней для Москвы, Казани, Санкт-Петербурга, Тулы и Новосибирска. В случае, если API отдает пустые значения за день, то их необходимо удалить.\n",
        "\n",
        "Информация должна быть представлена по часам с расширенным набором полей по осадкам.\n",
        "\n",
        "Полученный json необходимо преобразовать в csv, формат:\n",
        "\n",
        "\\begin{array}{ccc}\n",
        "\\text{city}, \\text{date}, \\text{hour}, \\text{temperature_c}, \\text{pressure_mm}, \\text{is_rainy} \\\\\n",
        "Moscow, 19.08.2023, 12, 27, 750, 0 \\\\\n",
        "Moscow, 19.08.2023, 13, 27, 750, 0 \\\\\n",
        "... \\\\\n",
        "Kazan, 19.08.2023, 12, 20, 770, 1 \\\\\n",
        "Kazan, 19.08.2023, 13, 21, 770, 0 \\\\\n",
        "\\end{array}\n",
        "\n",
        "**Описание полей:**\n",
        "\n",
        "city - Город\n",
        "\n",
        "date - Дата события\n",
        "\n",
        "hour - Часы\n",
        "\n",
        "temperature_c - Температура в Цельсиях\n",
        "\n",
        "pressure_mm - Давление в мм ртутного столба\n",
        "\n",
        "is_rainy - Флаг наличия дождя в конкретный день и час (см. документацию по API - описание полей).\n",
        "\n",
        "Полученный csv необходимо выгрузить на облачный диск и в конце решения предоставить ссылку.\n",
        "\n",
        "**Ссылка на получение ключа:** https://yandex.ru/dev/weather/doc/dg/concepts/about.html#about__onboarding\n",
        "\n",
        "\n",
        "**Дополнительно ответьте на вопросы:** какие существуют возможные пути ускорения получения данных по API и их преобразования? Возможно ли эти способы использовать в Airflow?"
      ],
      "metadata": {
        "id": "-bzGaxhZy3pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "import requests as req\n",
        "from geopy import geocoders\n",
        "\n",
        "TOKEN_YANDEX = \"80a4c74c-d6a7-4d51-ab31-e3d850aee839\"\n",
        "\n",
        "def geo_pos(city: str):\n",
        "    \"\"\"\n",
        "    Retrieve the geographical coordinates (latitude and longitude) of the given city.\n",
        "\n",
        "    Parameters:\n",
        "    - city: a string representing the name of the city\n",
        "\n",
        "    Return: a tuple containing the latitude and longitude of the city, or None if the coordinates cannot be retrieved\n",
        "    \"\"\"\n",
        "    geolocator = geocoders.Nominatim(user_agent=\"YaTest\")\n",
        "    location = geolocator.geocode(city)\n",
        "    if location:\n",
        "        latitude = location.latitude\n",
        "        longitude = location.longitude\n",
        "        return latitude, longitude\n",
        "    else:\n",
        "        print(f\"Failed to retrieve coordinates for {city}\")\n",
        "        return None\n",
        "\n",
        "def fill_coordinates(cities):\n",
        "    \"\"\"\n",
        "    Fill coordinates for each city in the input list using the geo_pos function.\n",
        "\n",
        "    Parameters:\n",
        "    - cities: a list of dictionaries, each containing information about a city including its name\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    for city in cities:\n",
        "        city_name = city[\"name\"]\n",
        "        coordinates = geo_pos(city_name)\n",
        "        if coordinates:\n",
        "            city[\"latitude\"], city[\"longitude\"] = coordinates\n",
        "\n",
        "def yandex_weather(latitude: float, longitude: float, token_yandex: str):\n",
        "    \"\"\"\n",
        "    Sends a request to the Yandex Weather API using the provided latitude, longitude, and Yandex API token.\n",
        "    Returns the weather forecast data in JSON format.\n",
        "    \"\"\"\n",
        "    url_yandex = f\"https://api.weather.yandex.ru/v2/forecast/\"\n",
        "    params = {\"lat\": latitude, \"lon\": longitude, \"lang\": \"ru_RU\"}\n",
        "    headers = {\"X-Yandex-API-Key\": token_yandex}\n",
        "    yandex_req = req.get(url_yandex, headers=headers, params=params)\n",
        "    if yandex_req.status_code != 200:\n",
        "        print(f\"Error {yandex_req.status_code} in request\")\n",
        "        return None\n",
        "    yandex_json = yandex_req.json()\n",
        "\n",
        "    return yandex_json\n",
        "\n",
        "def convert_to_csv(city: str, forecast_data):\n",
        "    \"\"\"\n",
        "    Convert the forecast data for a given city into a CSV format.\n",
        "\n",
        "    Parameters:\n",
        "    - city: the name of the city for which the forecast data is being converted\n",
        "    - forecast_data: the forecast data containing information about the weather\n",
        "\n",
        "    Returns:\n",
        "    A list of lists representing the CSV rows, each containing city, date, hour, temperature in Celsius, pressure in mm, rainy indicator, and condition\n",
        "    \"\"\"\n",
        "    csv_rows = []\n",
        "\n",
        "    for forecast in forecast_data[\"forecasts\"]:\n",
        "        date = forecast[\"date\"]\n",
        "        if \"hours\" not in forecast:\n",
        "            continue\n",
        "\n",
        "        for hour_data in forecast[\"hours\"]:\n",
        "            hour = hour_data[\"hour\"]\n",
        "            temperature_c = hour_data.get(\"temp\", \"N/A\")\n",
        "            pressure_mm = hour_data.get(\"pressure_mm\", \"N/A\")\n",
        "            is_rainy = 1 if hour_data.get(\"prec_mm\", 0) > 0 else 0\n",
        "            condition = hour_data.get(\"condition\", \"N/A\")\n",
        "\n",
        "            row = [city, date, hour, temperature_c, pressure_mm, is_rainy, condition]\n",
        "            csv_rows.append(row)\n",
        "\n",
        "    return csv_rows\n"
      ],
      "metadata": {
        "id": "yZI0bBf1099Q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check coordinates for cities\n",
        "cities = [\n",
        "    {\"name\": \"Moscow\", },\n",
        "    {\"name\": \"Kazan\", },\n",
        "    {\"name\": \"Saint Petersburg\", },\n",
        "    {\"name\": \"Tula\", },\n",
        "    {\"name\": \"Novosibirsk\", },\n",
        "]\n",
        "\n",
        "fill_coordinates(cities)\n",
        "\n",
        "for city in cities:\n",
        "    print(f\"{city['name']}: Latitude - {city.get('latitude', 'N/A')}, Longitude - {city.get('longitude', 'N/A')}\")\n",
        "\n",
        "if cities:\n",
        "    print(\"\\nok\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2bPiCgn91N0",
        "outputId": "3e7bbf60-f7cd-4375-f948-aee4dc6e6562"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moscow: Latitude - 55.625578, Longitude - 37.6063916\n",
            "Kazan: Latitude - 40.2054445, Longitude - 32.6813148\n",
            "Saint Petersburg: Latitude - 59.9606739, Longitude - 30.1586551\n",
            "Tula: Latitude - 45.2678347, Longitude - 1.7706797\n",
            "Novosibirsk: Latitude - 54.96781445, Longitude - 82.95159894278376\n",
            "\n",
            "ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    A function to collect weather data for a list of cities and save it in a CSV file.\n",
        "    \"\"\"\n",
        "    csv_rows = []\n",
        "    cities = [\n",
        "        {\"name\": \"Moscow\", },\n",
        "        {\"name\": \"Kazan\", },\n",
        "        {\"name\": \"Saint Petersburg\", },\n",
        "        {\"name\": \"Tula\", },\n",
        "        {\"name\": \"Novosibirsk\", },\n",
        "    ]\n",
        "\n",
        "    for city in cities:\n",
        "        # Get coordinates\n",
        "        coordinates = geo_pos(city[\"name\"])\n",
        "\n",
        "        if coordinates:\n",
        "            latitude, longitude = coordinates\n",
        "            # Get weather\n",
        "            weather_data = yandex_weather(latitude, longitude, TOKEN_YANDEX)\n",
        "            if weather_data:\n",
        "                # Преобразуем данные о погоде в CSV формат\n",
        "                city_rows = convert_to_csv(city[\"name\"], weather_data)\n",
        "                csv_rows.extend(city_rows)\n",
        "\n",
        "    # write in csv file\n",
        "    with open('weather_data.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
        "        csv_header = ['city', 'date', 'hour', 'temperature_c', 'pressure_mm', 'is_rainy', 'condition']\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(csv_header)\n",
        "        csv_writer.writerows(csv_rows)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "mCzHbE2KFkq0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ускорение получения данных из API** и их преобразования может быть достигнуто несколькими способами:\n",
        "\n",
        "- Пакетная обработка данных: Вместо того, чтобы делать отдельные запросы для каждого города, можно отправить запрос для нескольких городов одновременно.\n",
        "\n",
        "- Асинхронные запросы: Выполнения нескольких запросов параллельно. Можно использовать, поскольку результаты запросов для отдельных городов никак не влияют друг на друга.\n",
        "\n",
        "С этими способами может помочь **Apache Airflow**:\n",
        "\n",
        "- Планирование задач: Airflow позволяет планировать и запускать задачи по определенным правилам, что полезно для аинхронного кода.\n",
        "\n",
        "- Декомпозиция задач: Можно разбить пайплайн на набор задач с учетом их зависимостей. Это поможет оптимизировать параллельное выполнение и сделать пайплайн более масштабируемым."
      ],
      "metadata": {
        "id": "XVBLZEoPauyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "####2. Загрузка данных в БД (PostgreSQL).\n",
        "\n",
        "Используя полученный csv файл, необходимо загрузить данных в PostgreSQL. Предварительно в БД необходимо создать схемы: для приемки сырых данных и для будущих агрегирующих таблиц.\n",
        "\n",
        "При создании таблиц приветствуется использование партицирования и индексирования (по возможности и необходимости).\n",
        "\n",
        "В решении необходимо показать код загрузки данных, скрипты создания схем и таблиц для пункта 2 и 2.1.\n",
        "\n",
        "Подсказка: для решения задачи нужно развернуть БД, мы рекомендуем это сделать локально с помощью докера."
      ],
      "metadata": {
        "id": "HOAEAH0kzCAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разворачиваем psql в docker.\n",
        "\n",
        "Для этого выполним следующие команды\n",
        "\n",
        "Здесь `852c07c3682d` - ваш CONTAINER id, который можно посмотреть командой `docker ps`\n",
        "\n",
        "```docker  \n",
        "docker-compose up -d\n",
        "docker ps\n",
        "# Копирвоание скриптов на создание\n",
        "docker cp 'C:\\Users\\user\\OneDrive\\Документы\\GitHub\\internships\\API Яндекс.Погоды\\create_t.sql' 852c07c3682d:/tmp/\n",
        "docker cp 'C:\\Users\\user\\OneDrive\\Документы\\GitHub\\internships\\API Яндекс.Погоды\\weather_data.csv' 852c07c3682d:/tmp/\n",
        "docker cp 'C:\\Users\\user\\OneDrive\\Документы\\GitHub\\internships\\API Яндекс.Погоды\\load_data.sql' 852c07c3682d:/tmp/\n",
        "# Запуск команд на копирвоание данных в БД\n",
        "docker exec -i 852c07c3682d psql -U karnaksp -d test_api -a -f /tmp/create_t.sql\n",
        "docker exec -i 852c07c3682d psql -U karnaksp -d test_api -a -f /tmp/load_data.sql\n",
        "# Копирвоание скриптов на создание витрин\n",
        "docker cp 'C:\\Users\\user\\OneDrive\\Документы\\GitHub\\internships\\API Яндекс.Погоды\\weather_moving.sql' 852c07c3682d:/tmp/\n",
        "docker cp 'C:\\Users\\user\\OneDrive\\Документы\\GitHub\\internships\\API Яндекс.Погоды\\weather_rainy.sql' 852c07c3682d:/tmp/\n",
        "# Запуск скриптов на создание витрин\n",
        "docker exec -i 852c07c3682d psql -U karnaksp -d test_api -a -f /tmp/weather_moving.sql\n",
        "docker exec -i 852c07c3682d psql -U karnaksp -d test_api -a -f /tmp/weather_rainy.sql\n",
        "# Проверка\n",
        "docker exec -i 852c07c3682d psql -U karnaksp -d test_api -c \"SELECT * FROM aggregated_data.weather_aggregate limit 5;\"\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "m6GDZ5usDNhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Содержимое файла docker-compose.yaml**\n",
        "\n",
        "```\n",
        "version: '3.8'\n",
        "\n",
        "services:\n",
        "  postgres:\n",
        "    image: postgres:latest\n",
        "    environment:\n",
        "      POSTGRES_DB: test_api\n",
        "      POSTGRES_USER: karnaksp\n",
        "      POSTGRES_PASSWORD: a1s2s3\n",
        "    ports:\n",
        "      - \"5432:5432\"\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "exKGBlEPDu0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "--Здесь представлены скрипты sql--\n",
        "\n",
        "--Создание схем--\n",
        "CREATE SCHEMA raw_data;\n",
        "CREATE SCHEMA aggregated_data;\n",
        "--Создание первичной таблицы--\n",
        "CREATE TABLE IF NOT EXISTS raw_data.weather_data (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    city VARCHAR(255),\n",
        "    date DATE,\n",
        "    hour INT,\n",
        "    temperature_c INT,\n",
        "    pressure_mm INT,\n",
        "    is_rainy INT,\n",
        "    condition VARCHAR(255)\n",
        ");\n",
        "\n",
        "--Загрузка данных--\n",
        "COPY raw_data.weather_data(city, date, hour, temperature_c, pressure_mm, is_rainy, condition)\n",
        "FROM '/tmp/weather_data.csv' DELIMITER ',' CSV HEADER;\n",
        "```\n"
      ],
      "metadata": {
        "id": "IiNwevI-Gfxb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Isa3SMnxyudM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2.1 Формирование витрин (PostgreSQL).\n",
        "\n",
        "1. Используя таблицу с сырыми данными, необходимо собрать витрину, где для каждого города и дня будут указаны часы начала дождя. Условимся, что дождь может начаться только 1 раз за день в любом из городов.\n",
        "\n",
        "2. Необходимо создать витрину, где для каждого города, дня и часа будет рассчитано скользящее среднее по температуре и по давлению.\n",
        "\n",
        "\n",
        "Полученные запросы необходимо вставить в google colab, а результаты - выгрузить в формате csv/xlsx и выложить в виде ссылки в google colab.\n",
        "\n",
        "Подсказка: если в исходном файле не было факта начала дождя, то необходимо расставить рандомно значения факта дождя в таблице с сырыми данными.\n"
      ],
      "metadata": {
        "id": "kcubMA6zqy5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```sql\n",
        "--Создание и заполнение витрин--\n",
        "--Час начала дождя--\n",
        "CREATE TABLE IF NOT EXISTS aggregated_data.weather_aggregate (\n",
        "    city VARCHAR(255),\n",
        "    date DATE,\n",
        "    start_rain_hour INT,\n",
        "    temperature_avg FLOAT,\n",
        "    pressure_avg FLOAT\n",
        ");\n",
        "\n",
        "INSERT INTO aggregated_data.weather_aggregate (city, date, start_rain_hour, temperature_avg, pressure_avg)\n",
        "SELECT\n",
        "    city,\n",
        "    date,\n",
        "    MIN(hour) AS start_rain_hour,\n",
        "FROM\n",
        "    raw_data.weather_data\n",
        "WHERE\n",
        "    is_rainy = 1\n",
        "GROUP BY\n",
        "    city, date;\n",
        "\n",
        "--Скользящие средние показатели--\n",
        "CREATE TABLE IF NOT EXISTS aggregated_data.hourly_aggregate (\n",
        "    city VARCHAR(255),\n",
        "    date DATE,\n",
        "    hour INT,\n",
        "    temperature_avg FLOAT,\n",
        "    pressure_avg FLOAT\n",
        ");\n",
        "\n",
        "INSERT INTO aggregated_data.hourly_aggregate (city, date, hour, temperature_avg, pressure_avg)\n",
        "SELECT\n",
        "    city,\n",
        "    date,\n",
        "    hour,\n",
        "    AVG(temperature_c) OVER (PARTITION BY city, date ORDER BY hour ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS temperature_avg,\n",
        "    AVG(pressure_mm) OVER (PARTITION BY city, date ORDER BY hour ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS pressure_avg\n",
        "FROM\n",
        "    raw_data.weather_data;\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "bVT-A76ZHjh9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TopO7d8GvR6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "####3. Задача на проектирование БД на данных Яндекс.Метрики\n",
        "\n",
        "В функционал Яндекс.Метрики входит возможность выкачивания сырых данных с помощью API: отдельными запросами выкачиваются просмотры и визиты. Для этого процесса необходимо спроектировать базу данных, предусмотрев несколько слоев данных и \"хотелки\" заказчиков: в 90% случаев заказчикам необходимы агрегаты данных (например, построить воронку по визитам на страницах и вводу номеров телефонов в разрезе дат, страниц, utm меток, или построить флоу пользователей в разрезе устройств, ОС, и т.д.).\n",
        "\n",
        "Результат необходимо предоставить в виде схемы с описанием.\n",
        "\n",
        "Ссылки на структуру таблиц:\n",
        "\n",
        "https://yandex.ru/dev/metrika/doc/api2/logs/fields/hits.html\n",
        "\n",
        "https://yandex.ru/dev/metrika/doc/api2/logs/fields/visits.html"
      ],
      "metadata": {
        "id": "88tCFTCbzPv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# При переходе по ссылкам вывод: limited"
      ],
      "metadata": {
        "id": "z8dugnICyufe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvvgDAhQyuh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCi92VAFyukW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}